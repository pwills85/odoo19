# üéØ PROMPT PROFESIONAL: CIERRE BRECHAS SPRINT 2 - VALIDACI√ìN Y CONTINUACI√ìN

**Versi√≥n:** 8.0 (Post-An√°lisis Cr√≠tico Sesi√≥n 40min)  
**Fecha:** 2025-11-09  
**Proyecto:** EERGYGROUP Odoo 19 CE - AI Service  
**Base:** ANALISIS_CRITICO_SPRINT2_SESION_40MIN_2025-11-09.md  
**Metodolog√≠a:** Evidence-Based, Test-Driven, Coverage Verification Mandatory  
**Objetivo:** Resolver discrepancia coverage y alcanzar ‚â•80%

---

## üìã CONTEXTO EJECUTIVO - ESTADO POST-40MIN

### üî¥ PROBLEMA CR√çTICO DETECTADO

**Discrepancia Coverage:**

| M√©trica | Claim Agente | Real Verificado | Discrepancia |
|---------|--------------|-----------------|--------------|
| **Coverage Total** | 41-50% | **15.82%** | **-25 a -34%** üî¥ |
| **Tests Creados** | 24 | ‚úÖ 24 verificado | ‚úÖ CORRECTO |
| **Tests Colectados** | 223 | ‚úÖ 223 verificado | ‚úÖ CORRECTO |
| **Commits** | 4 | ‚úÖ 4 verificado | ‚úÖ CORRECTO |

**Root Cause Posible:**
1. Coverage medido de `main.py` espec√≠fico (41%) vs total proyecto (15.82%)
2. Tests con mocks excesivos (NO ejecutan c√≥digo real)
3. Tests colectados pero fallan/skip silenciosamente

### ‚úÖ Progreso Verificado (40 min trabajo)

```
Fase 2.0: Pre-validation         ‚úÖ COMPLETO (commit a7fc36e4)
Fase 2.1: Fix SYSTEM_PROMPT_BASE ‚úÖ COMPLETO (commit 0dcc15bf)
Fase 2.2 Batch 1: 16 tests       ‚úÖ COMPLETO (commit b3e69bc0)
Fase 2.2 Batch 2: 8 tests        ‚ö†Ô∏è CREADO (NOT committed)
Fase 2.3-2.4: Coverage 80%       ‚è∏Ô∏è BLOQUEADO (pending validation)

Tiempo Usado: 40 min / 6-8h (8%)
Coverage Real: 15.82% (gap: -64.18% to target 80%)
```

---

## üéØ OBJETIVO DEL PROMPT

**Alcance:**
1. ‚úÖ **VALIDAR** coverage real (22 min - CR√çTICO)
2. ‚úÖ **COMMIT** trabajo Batch 2 pendiente (2 min)
3. ‚úÖ **DECIDIR** estrategia seg√∫n resultados validaci√≥n
4. ‚úÖ **EJECUTAR** Fase 2.3-2.4 con metodolog√≠a corregida
5. ‚úÖ **ALCANZAR** coverage ‚â•80% con tests efectivos

**Resultado Esperado:**
- Coverage: 15.82% ‚Üí ‚â•80% (+64.18%)
- Tests: 223 ‚Üí ~300-350 (estimado +100-150 tests efectivos)
- Score AI: 87/100 ‚Üí 103/100 (+16 pts)
- Metodolog√≠a: Coverage verification MANDATORY cada batch

**Tiempo Total:** 5-8 horas (depende validaci√≥n)

---

## üî¥ FASE CR√çTICA: VALIDACI√ìN COVERAGE (MANDATORY - 22 MIN)

### ‚ö†Ô∏è EJECUTAR ANTES DE CONTINUAR

**Problema:** Discrepancia -25 a -34% entre claim y realidad requiere investigaci√≥n.

### Paso 1: Medir Coverage Real (5 min)

```bash
# 1.1 Coverage TOTAL proyecto
docker exec odoo19_ai_service pytest --cov=. --cov-report=term --cov-report=json -q 2>&1 | tee /tmp/sprint2_coverage_total.txt

# Extraer m√©trica
grep "TOTAL" /tmp/sprint2_coverage_total.txt | awk '{print "Coverage TOTAL:", $4}'

# 1.2 Coverage main.py ESPEC√çFICO
docker exec odoo19_ai_service pytest --cov=main --cov-report=term-missing -q 2>&1 | tee /tmp/sprint2_coverage_main.txt

# Extraer m√©trica
grep "main.py" /tmp/sprint2_coverage_main.txt | awk '{print "Coverage main.py:", $4}'

# 1.3 Coverage por archivo cr√≠tico
docker exec odoo19_ai_service pytest \
  --cov=main \
  --cov=chat/engine \
  --cov=clients/anthropic_client \
  --cov-report=term-missing -q 2>&1 | tee /tmp/sprint2_coverage_breakdown.txt

# 1.4 Documentar resultados
cat > /tmp/sprint2_coverage_validation.txt <<EOF
=== SPRINT 2 COVERAGE VALIDATION ===
Date: $(date +"%Y-%m-%d %H:%M:%S")

Coverage TOTAL:       $(grep "TOTAL" /tmp/sprint2_coverage_total.txt | awk '{print $4}')
Coverage main.py:     $(grep "main.py" /tmp/sprint2_coverage_main.txt | awk '{print $4}')
Coverage chat/engine: $(grep "chat/engine" /tmp/sprint2_coverage_breakdown.txt | awk '{print $4}')
Coverage anthropic:   $(grep "anthropic_client" /tmp/sprint2_coverage_breakdown.txt | awk '{print $4}')

Discrepancy Analysis:
- Claim:  41-50% total
- Real:   [SEE ABOVE]
- Delta:  [CALCULATE]

Root Cause: [TO BE DETERMINED]
EOF

cat /tmp/sprint2_coverage_validation.txt
```

**Checkpoint 1.0:** ‚úÖ Coverage real medido y documentado

---

### Paso 2: Validar Tests Efectividad (10 min)

```bash
# 2.1 Ejecutar tests del archivo nuevo
docker exec odoo19_ai_service pytest tests/integration/test_main_endpoints.py -v --tb=short 2>&1 | tee /tmp/sprint2_tests_execution.txt

# 2.2 Contar resultados
PASSED=$(grep -c "PASSED" /tmp/sprint2_tests_execution.txt || echo "0")
FAILED=$(grep -c "FAILED" /tmp/sprint2_tests_execution.txt || echo "0")
ERROR=$(grep -c "ERROR" /tmp/sprint2_tests_execution.txt || echo "0")
SKIPPED=$(grep -c "SKIPPED" /tmp/sprint2_tests_execution.txt || echo "0")

echo "Tests PASSED:  $PASSED / 24"
echo "Tests FAILED:  $FAILED / 24"
echo "Tests ERROR:   $ERROR / 24"
echo "Tests SKIPPED: $SKIPPED / 24"

# 2.3 Analizar mocks usage
echo ""
echo "=== MOCK ANALYSIS ==="
PATCHES=$(grep -c "@patch\|@mock" ai-service/tests/integration/test_main_endpoints.py || echo "0")
TESTCLIENT=$(grep -c "TestClient" ai-service/tests/integration/test_main_endpoints.py || echo "0")

echo "Mock/Patch decorators: $PATCHES"
echo "TestClient usage:      $TESTCLIENT"
echo "Ratio mocks/tests:     $(echo "scale=2; $PATCHES / 24" | bc)"

# 2.4 Test sample individual con coverage
echo ""
echo "=== TESTING SAMPLE TEST COVERAGE ==="
docker exec odoo19_ai_service pytest \
  tests/integration/test_main_endpoints.py::test_health_endpoint \
  --cov=main --cov-report=term-missing -v 2>&1 | grep -A 5 "main.py"

# 2.5 Documentar an√°lisis
cat >> /tmp/sprint2_coverage_validation.txt <<EOF

=== TESTS EFFECTIVENESS ANALYSIS ===

Tests Execution:
- PASSED:  $PASSED / 24
- FAILED:  $FAILED / 24
- ERROR:   $ERROR / 24
- SKIPPED: $SKIPPED / 24

Mock Analysis:
- @patch/@mock decorators: $PATCHES
- Ratio mocks/tests:       $(echo "scale=2; $PATCHES / 24" | bc)

Effectiveness:
- If ratio > 0.5: ‚ö†Ô∏è Excessive mocks (tests may not execute real code)
- If PASSED < 20: ‚ö†Ô∏è Tests failing/skipping
- If coverage main.py < 30%: ‚ùå Tests NOT effective

EOF

cat /tmp/sprint2_coverage_validation.txt
```

**Checkpoint 2.0:** ‚úÖ Tests efectividad analizada y documentada

---

### Paso 3: Decisi√≥n Estrat√©gica (5 min)

```bash
# 3.1 Leer m√©tricas validadas
COVERAGE_TOTAL=$(grep "Coverage TOTAL:" /tmp/sprint2_coverage_validation.txt | awk '{print $3}' | sed 's/%//')
COVERAGE_MAIN=$(grep "Coverage main.py:" /tmp/sprint2_coverage_validation.txt | awk '{print $3}' | sed 's/%//')
TESTS_PASSED=$(grep "PASSED:" /tmp/sprint2_coverage_validation.txt | awk '{print $3}' | cut -d'/' -f1)

# 3.2 Determinar escenario
echo ""
echo "=== DECISION MATRIX ==="

if [ $(echo "$COVERAGE_MAIN > 35" | bc) -eq 1 ] && [ $TESTS_PASSED -gt 20 ]; then
    SCENARIO="A"
    echo "SCENARIO A: Tests Efectivos ‚úÖ"
    echo "- Coverage main.py: $COVERAGE_MAIN% (>35%)"
    echo "- Tests passing:    $TESTS_PASSED/24 (>20)"
    echo "- Decision:         CONTINUAR Fase 2.3 (otros archivos)"
    echo "- Root Cause:       Confusi√≥n metrics (main.py vs total)"
    echo "- ETA:              5-6h restantes"
elif [ $(echo "$COVERAGE_MAIN < 20" | bc) -eq 1 ] || [ $TESTS_PASSED -lt 15 ]; then
    SCENARIO="B"
    echo "SCENARIO B: Tests NO Efectivos ‚ùå"
    echo "- Coverage main.py: $COVERAGE_MAIN% (<20%)"
    echo "- Tests passing:    $TESTS_PASSED/24 (<15)"
    echo "- Decision:         REFACTORIZAR tests (quitar mocks)"
    echo "- Root Cause:       Mocks excesivos, tests NO ejecutan c√≥digo"
    echo "- ETA:              6.5-8.5h restantes (+1-2h refactor)"
else
    SCENARIO="C"
    echo "SCENARIO C: Parcial ‚ö†Ô∏è"
    echo "- Coverage main.py: $COVERAGE_MAIN% (20-35%)"
    echo "- Tests passing:    $TESTS_PASSED/24 (15-20)"
    echo "- Decision:         OPTIMIZAR tests + agregar m√°s"
    echo "- Root Cause:       Tests parcialmente efectivos"
    echo "- ETA:              6-7h restantes"
fi

# 3.3 Documentar decisi√≥n
cat >> /tmp/sprint2_coverage_validation.txt <<EOF

=== DECISION ===

Scenario:   $SCENARIO
Coverage:   $COVERAGE_MAIN% main.py, $COVERAGE_TOTAL% total
Tests:      $TESTS_PASSED/24 passing
Strategy:   [SEE ABOVE]
ETA:        [SEE ABOVE]

Next Steps: Execute Fase 2.3+ seg√∫n Scenario $SCENARIO
EOF

cat /tmp/sprint2_coverage_validation.txt
```

**Checkpoint 3.0:** ‚úÖ Escenario identificado, estrategia definida

---

### Paso 4: Commit Trabajo Pendiente (2 min)

```bash
# 4.1 Verificar cambios no commiteados
git status | grep "test_main_endpoints.py"

# 4.2 Commit Batch 2
git add ai-service/tests/integration/test_main_endpoints.py
git commit -m "test(main): add Batch 2 integration tests (8 additional)

SPRINT 2 - Fase 2.2 Batch 2

Tests Added: 8 (payroll, SII validation)
Total Tests: 24 in test_main_endpoints.py
Coverage:
- main.py:  $COVERAGE_MAIN% (measured)
- Total:    $COVERAGE_TOTAL% (measured)

Scenario: $SCENARIO
Status: Tests created, effectiveness validation complete

Related: SPRINT 2 Coverage target 80%
Validation: /tmp/sprint2_coverage_validation.txt
"

# 4.3 Git tag checkpoint
git tag -a sprint2_batch2_validation_$(date +%Y%m%d_%H%M) -m "SPRINT 2 Batch 2 validation complete - Scenario $SCENARIO"

echo "‚úÖ Commit y tag creados"
```

**Checkpoint 4.0:** ‚úÖ Trabajo pendiente guardado con evidencia

---

## üîÄ BIFURCACI√ìN SEG√öN ESCENARIO

### SCENARIO A: Tests Efectivos (Coverage main.py >35%)

**Diagn√≥stico:**
- ‚úÖ Tests ejecutan c√≥digo real
- ‚úÖ Coverage main.py avanzando
- ‚ö†Ô∏è Coverage total bajo porque solo main.py mejorado

**Estrategia:** CONTINUAR Fase 2.3 (otros archivos)

**Pasar a:** [FASE 2.3 - SCENARIO A](#fase-23-scenario-a-coverage-otros-archivos)

---

### SCENARIO B: Tests NO Efectivos (Coverage main.py <20%)

**Diagn√≥stico:**
- ‚ùå Tests NO ejecutan c√≥digo real
- ‚ùå Mocks excesivos bloquean ejecuci√≥n
- üî¥ BLOQUEANTE: Refactor necesario antes continuar

**Estrategia:** REFACTORIZAR tests Batch 1+2

**Pasar a:** [FASE 2.2B - SCENARIO B](#fase-22b-scenario-b-refactor-tests)

---

### SCENARIO C: Parcial (Coverage main.py 20-35%)

**Diagn√≥stico:**
- ‚ö†Ô∏è Tests parcialmente efectivos
- ‚ö†Ô∏è Algunos mocks innecesarios
- ‚úÖ Optimizaci√≥n + tests adicionales

**Estrategia:** OPTIMIZAR + CONTINUAR

**Pasar a:** [FASE 2.2C - SCENARIO C](#fase-22c-scenario-c-optimizar-y-continuar)

---

## üéØ FASE 2.3 - SCENARIO A: COVERAGE OTROS ARCHIVOS

**Pre-Requisitos:**
- ‚úÖ Scenario A validado (main.py >35%)
- ‚úÖ Commit Batch 2 guardado
- ‚úÖ 24 tests efectivos funcionando

### Fase 2.3a: Coverage chat/engine.py (1.5-2h)

**Target:** 14% ‚Üí 85% (+132 stmts, ~25-30 tests)

**Archivo:** `ai-service/chat/engine.py` (658 LOC)

#### Pre-An√°lisis Coverage

```bash
# 1. Identificar m√©todos sin coverage
docker exec odoo19_ai_service pytest --cov=chat/engine --cov-report=term-missing -q 2>&1 | grep "chat/engine.py" -A 20 > /tmp/engine_coverage_missing.txt

# 2. Listar m√©todos principales
grep "^\s*def " ai-service/chat/engine.py | grep -v "^\s*def _" | nl

# 3. Priorizar por uso (grep en tests existentes)
for method in $(grep "^\s*def " ai-service/chat/engine.py | grep -v "^\s*def _" | awk '{print $2}' | cut -d'(' -f1); do
    count=$(grep -r "$method" ai-service/tests --include="*.py" | wc -l)
    echo "$count tests - $method"
done | sort -rn | head -15

# 4. Identificar gaps cr√≠ticos
echo "=== M√âTODOS SIN TESTS ===" > /tmp/engine_methods_gaps.txt
grep "^\s*def " ai-service/chat/engine.py | grep -v "^\s*def _" | while read line; do
    method=$(echo "$line" | awk '{print $2}' | cut -d'(' -f1)
    count=$(grep -r "$method" ai-service/tests --include="*.py" | wc -l)
    if [ $count -eq 0 ]; then
        echo "‚ùå $method (0 tests)" >> /tmp/engine_methods_gaps.txt
    fi
done

cat /tmp/engine_methods_gaps.txt
```

#### Tests a Crear (25-30 tests)

**Crear archivo:** `ai-service/tests/unit/test_chat_engine_extended.py`

```python
"""Extended tests for ChatEngine - Coverage gaps"""

import pytest
from unittest.mock import Mock, patch, AsyncMock
from chat.engine import ChatEngine
from config import Settings

class TestChatEngineCore:
    """Tests para m√©todos core sin coverage"""
    
    @pytest.fixture
    def engine(self):
        """ChatEngine instance con config test"""
        settings = Settings(
            anthropic_api_key="test_key",
            model="claude-3-5-sonnet-20241022"
        )
        return ChatEngine(settings)
    
    @pytest.mark.asyncio
    async def test_process_message_basic_flow(self, engine):
        """process_message debe manejar flujo b√°sico correctamente"""
        with patch.object(engine.client, 'send_message', new_callable=AsyncMock) as mock_send:
            mock_send.return_value = {
                'content': 'Test response',
                'usage': {'input_tokens': 10, 'output_tokens': 20}
            }
            
            result = await engine.process_message(
                messages=[{'role': 'user', 'content': 'Test'}],
                context={}
            )
            
            assert result['content'] == 'Test response'
            assert result['usage']['input_tokens'] == 10
            mock_send.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_process_message_with_knowledge_base(self, engine):
        """process_message debe integrar knowledge base cuando disponible"""
        with patch.object(engine, '_get_knowledge_context', return_value={'docs': ['doc1']}) as mock_kb:
            with patch.object(engine.client, 'send_message', new_callable=AsyncMock) as mock_send:
                mock_send.return_value = {'content': 'KB response', 'usage': {}}
                
                result = await engine.process_message(
                    messages=[{'role': 'user', 'content': 'Query KB'}],
                    use_kb=True
                )
                
                mock_kb.assert_called_once()
                assert result['content'] == 'KB response'
    
    @pytest.mark.asyncio
    async def test_process_message_error_handling(self, engine):
        """process_message debe manejar errores de API correctamente"""
        with patch.object(engine.client, 'send_message', new_callable=AsyncMock) as mock_send:
            mock_send.side_effect = Exception("API Error")
            
            with pytest.raises(Exception) as exc_info:
                await engine.process_message(
                    messages=[{'role': 'user', 'content': 'Test'}]
                )
            
            assert "API Error" in str(exc_info.value)
    
    def test_format_messages_validates_structure(self, engine):
        """format_messages debe validar estructura de mensajes"""
        messages = [
            {'role': 'user', 'content': 'Hello'},
            {'role': 'assistant', 'content': 'Hi'}
        ]
        
        formatted = engine.format_messages(messages)
        
        assert len(formatted) == 2
        assert all('role' in msg for msg in formatted)
        assert all('content' in msg for msg in formatted)
    
    def test_format_messages_filters_invalid(self, engine):
        """format_messages debe filtrar mensajes inv√°lidos"""
        messages = [
            {'role': 'user', 'content': 'Valid'},
            {'role': 'invalid'},  # Sin content
            {'content': 'No role'}  # Sin role
        ]
        
        formatted = engine.format_messages(messages)
        
        assert len(formatted) == 1
        assert formatted[0]['role'] == 'user'
    
    # ... 20-25 tests m√°s para cubrir m√©todos restantes
```

**Proceso Implementaci√≥n:**

```bash
# 1. Crear archivo test (iterativo, 5 tests a la vez)
touch ai-service/tests/unit/test_chat_engine_extended.py

# 2. Implementar 5 tests
# (usar editor)

# 3. Ejecutar tests SOLO de este archivo
docker exec odoo19_ai_service pytest tests/unit/test_chat_engine_extended.py -v

# 4. Medir coverage incremental
docker exec odoo19_ai_service pytest --cov=chat/engine --cov-report=term-missing tests/unit/test_chat_engine_extended.py -v | tee /tmp/engine_coverage_batch1.txt

# 5. Commit cada 5-10 tests
git add ai-service/tests/unit/test_chat_engine_extended.py
git commit -m "test(chat_engine): add 5 core method tests

Coverage chat/engine: XX% ‚Üí YY% (+ZZ%)
Tests: test_process_message_*, test_format_messages_*
Lines covered: [LIST]
"

# 6. Repetir hasta coverage ‚â•85%
```

**Checkpoint 2.3a:** ‚úÖ `chat/engine.py` coverage ‚â•85%

---

### Fase 2.3b: Coverage clients/anthropic_client.py (1h)

**Target:** 14% ‚Üí 85% (+74 stmts, ~15-20 tests)

**Proceso similar a 2.3a:**
1. Identificar m√©todos sin coverage
2. Crear `test_anthropic_client_extended.py`
3. Implementar tests 5 a la vez
4. Medir coverage incremental
5. Commit cada batch

**Checkpoint 2.3b:** ‚úÖ `anthropic_client.py` coverage ‚â•85%

---

### Fase 2.3c-e: Coverage Otros M√≥dulos (2-3h)

**Targets:**
- chat/kb.py, chat/context.py: ‚Üí70% (+176 stmts)
- plugins/loader.py, plugins/registry.py: ‚Üí60% (+217 stmts)
- utils cr√≠ticos: ‚Üí60% (+180 stmts)

**Proceso:** Similar a 2.3a-b, priorizando archivos cr√≠ticos

---

### Fase 2.4: Validaci√≥n Final y Score (30 min)

```bash
# 1. Coverage final
docker exec odoo19_ai_service pytest --cov=. --cov-report=term --cov-report=json --cov-fail-under=80 -v 2>&1 | tee /tmp/sprint2_coverage_final.txt

# 2. Extraer m√©tricas
COVERAGE_FINAL=$(grep "TOTAL" /tmp/sprint2_coverage_final.txt | awk '{print $4}' | sed 's/%//')

# 3. Tests status
docker exec odoo19_ai_service pytest -v --tb=no 2>&1 | tee /tmp/sprint2_tests_final.txt
TESTS_PASSED=$(grep -c "PASSED" /tmp/sprint2_tests_final.txt)
TESTS_FAILED=$(grep -c "FAILED" /tmp/sprint2_tests_final.txt)
TESTS_ERROR=$(grep -c "ERROR" /tmp/sprint2_tests_final.txt)

# 4. Calcular score
cat > /tmp/sprint2_score_final.txt <<EOF
=== SPRINT 2 SCORE FINAL ===

Baseline: 82/100

Bonificaciones:
+ P1-1 (Coverage ‚â•80%): +7 pts ($COVERAGE_FINAL%)
+ P1-2 (TODOs complete): +3 pts
+ P1-3 (Redis HA): +2 pts
+ P1-4 (pytest config): +1 pt
+ P1-5 (Integration 0 ERROR): +3 pts
+ P2 (KB+Health+Prom): +3 pts
+ P3 (Docs+Rate): +2 pts

Penalties:
- Tests FAILED: $(if [ $TESTS_FAILED -gt 10 ]; then echo "-2 pts"; else echo "0 pts"; fi)

SCORE FINAL: $(if [ $(echo "$COVERAGE_FINAL >= 80" | bc) -eq 1 ]; then echo "103/100 ‚úÖ"; else echo "96/100 ‚ö†Ô∏è"; fi)
EOF

cat /tmp/sprint2_score_final.txt

# 5. Git tag final
git tag -a sprint2_complete_$(date +%Y%m%d_%H%M) -m "SPRINT 2 Complete: Coverage $COVERAGE_FINAL%"

# 6. Commit final
git add .
git commit -m "feat(sprint2): complete coverage sprint - ${COVERAGE_FINAL}% achieved

SPRINT 2 COMPLETE:
- Coverage: 15.82% ‚Üí ${COVERAGE_FINAL}% (+$(echo "$COVERAGE_FINAL - 15.82" | bc)%)
- Tests: 223 ‚Üí $(grep -c "collected" /tmp/sprint2_tests_final.txt) (+$(echo "$(grep -c "collected" /tmp/sprint2_tests_final.txt) - 223" | bc))
- Score AI: 87/100 ‚Üí $(grep "SCORE FINAL" /tmp/sprint2_score_final.txt | awk '{print $3}')
- Production ready: $(if [ $(echo "$COVERAGE_FINAL >= 80" | bc) -eq 1 ]; then echo "YES ‚úÖ"; else echo "NO ‚ö†Ô∏è"; fi)

Files improved: main.py, chat/engine.py, anthropic_client.py, [OTHERS]
Tests created: ~100-150 nuevos tests
Methodology: Evidence-Based, Coverage Verification Mandatory
"
```

**Checkpoint 2.4:** ‚úÖ Coverage ‚â•80%, Score calculado, SPRINT 2 COMPLETO

---

## üîß FASE 2.2B - SCENARIO B: REFACTOR TESTS

**Pre-Requisitos:**
- ‚ö†Ô∏è Scenario B detectado (main.py <20%)
- üî¥ Tests NO efectivos (mocks excesivos)
- Commit Batch 2 guardado

### Diagn√≥stico Profundo (30 min)

```bash
# 1. Analizar tests actuales l√≠nea por l√≠nea
cat ai-service/tests/integration/test_main_endpoints.py | grep -n "@patch\|@mock\|TestClient" > /tmp/tests_analysis.txt

# 2. Identificar patterns problem√°ticos
echo "=== PROBLEMATIC PATTERNS ===" > /tmp/tests_refactor_plan.txt

# Pattern 1: Mock app completo
grep -n "@patch.*main.app" ai-service/tests/integration/test_main_endpoints.py | while read line; do
    echo "‚ùå Line $line: Mocking entire app (0% coverage)" >> /tmp/tests_refactor_plan.txt
done

# Pattern 2: Mock settings globales
grep -n "@patch.*config.settings" ai-service/tests/integration/test_main_endpoints.py | while read line; do
    echo "‚ö†Ô∏è Line $line: Mocking settings (reduce coverage)" >> /tmp/tests_refactor_plan.txt
done

# Pattern 3: TestClient sin mocks (BUENO)
grep -n "TestClient" ai-service/tests/integration/test_main_endpoints.py | while read line; do
    echo "‚úÖ Line $line: TestClient usage (good)" >> /tmp/tests_refactor_plan.txt
done

cat /tmp/tests_refactor_plan.txt

# 3. Contar tests por patr√≥n
MOCK_APP=$(grep -c "@patch.*main.app" ai-service/tests/integration/test_main_endpoints.py || echo "0")
MOCK_SETTINGS=$(grep -c "@patch.*config.settings" ai-service/tests/integration/test_main_endpoints.py || echo "0")
TESTCLIENT_ONLY=$(grep -c "TestClient" ai-service/tests/integration/test_main_endpoints.py || echo "0")

echo ""
echo "Tests con @patch app:      $MOCK_APP (ELIMINAR)"
echo "Tests con @patch settings: $MOCK_SETTINGS (MINIMIZAR)"
echo "Tests con TestClient:      $TESTCLIENT_ONLY (MANTENER)"
```

### Refactorizaci√≥n Tests (1-2h)

**Estrategia:**
1. Identificar tests con mocks excesivos
2. Reescribir SIN mocks innecesarios
3. Usar TestClient directo (ejecuta c√≥digo real)
4. Mocks SOLO para dependencias externas (APIs, DB)

**Ejemplo Refactor:**

```python
# ‚ùå ANTES (0% coverage)
@patch('main.app.state')
@patch('config.settings')
def test_health_endpoint(mock_settings, mock_state):
    mock_settings.enable_health_checks = True
    client = TestClient(app)
    response = client.get("/health")
    assert response.status_code == 200

# ‚úÖ DESPU√âS (100% coverage)
def test_health_endpoint():
    """Test health endpoint ejecuta c√≥digo real"""
    from main import app
    client = TestClient(app)
    
    # TestClient ejecuta c√≥digo real de main.py
    response = client.get("/health")
    
    assert response.status_code == 200
    assert "status" in response.json()
    assert response.json()["status"] in ["healthy", "unhealthy"]
    # Coverage: Ejecut√≥ /health endpoint completo
```

**Proceso:**

```bash
# 1. Backup archivo original
cp ai-service/tests/integration/test_main_endpoints.py ai-service/tests/integration/test_main_endpoints.py.backup

# 2. Refactorizar 5 tests a la vez
# (usar editor, eliminar @patch innecesarios)

# 3. Ejecutar tests refactorizados
docker exec odoo19_ai_service pytest tests/integration/test_main_endpoints.py -v --tb=short

# 4. Medir coverage despu√©s refactor
docker exec odoo19_ai_service pytest --cov=main --cov-report=term-missing tests/integration/test_main_endpoints.py -v | tee /tmp/coverage_after_refactor.txt

# 5. Validar mejora
COVERAGE_BEFORE=$(grep "main.py" /tmp/sprint2_coverage_main.txt | awk '{print $4}')
COVERAGE_AFTER=$(grep "main.py" /tmp/coverage_after_refactor.txt | awk '{print $4}')

echo "Coverage BEFORE refactor: $COVERAGE_BEFORE"
echo "Coverage AFTER refactor:  $COVERAGE_AFTER"
echo "Improvement:              +$(echo "$COVERAGE_AFTER - $COVERAGE_BEFORE" | bc | sed 's/%//')%"

# 6. Commit refactor
git add ai-service/tests/integration/test_main_endpoints.py
git commit -m "refactor(tests): remove excessive mocks - improve coverage effectiveness

PROBLEM:
- Tests had excessive @patch decorators
- Mocked entire app/settings (0% real code execution)
- Coverage main.py stuck at ${COVERAGE_BEFORE}%

SOLUTION:
- Removed unnecessary @patch('main.app') decorators
- Use TestClient directly (executes real code)
- Mock ONLY external dependencies (APIs, DB)

RESULTS:
- Coverage main.py: ${COVERAGE_BEFORE}% ‚Üí ${COVERAGE_AFTER}% (+$(echo "$COVERAGE_AFTER - $COVERAGE_BEFORE" | bc)%)
- Tests still passing: $(grep -c "PASSED" /tmp/coverage_after_refactor.txt)/24
- Real code execution: ‚úÖ

Fixes: SPRINT 2 Scenario B (tests not effective)
"

# 7. Si coverage ahora >35%: CONTINUAR Fase 2.3 (Scenario A)
if [ $(echo "$COVERAGE_AFTER > 35" | bc | sed 's/%//') -eq 1 ]; then
    echo "‚úÖ Coverage mejorado, cambiar a Scenario A"
    echo "Ejecutar: FASE 2.3 - SCENARIO A"
else
    echo "‚ö†Ô∏è Coverage a√∫n bajo, agregar m√°s tests efectivos"
fi
```

**Checkpoint 2.2B:** ‚úÖ Tests refactorizados, coverage main.py >35%

**Siguiente Paso:** Continuar con Fase 2.3 (Scenario A)

---

## üîÄ FASE 2.2C - SCENARIO C: OPTIMIZAR Y CONTINUAR

**Pre-Requisitos:**
- ‚ö†Ô∏è Scenario C detectado (main.py 20-35%)
- Tests parcialmente efectivos
- Optimizaci√≥n + tests adicionales necesarios

### Estrategia H√≠brida (2-3h)

1. **Optimizar tests existentes** (30 min)
   - Reducir mocks innecesarios (no todos)
   - Mejorar asserts (validar m√°s)
   - Agregar casos edge

2. **Agregar tests para gaps** (1.5h)
   - Identificar l√≠neas NO ejecutadas
   - Crear tests espec√≠ficos para esas l√≠neas
   - Usar `--cov-report=term-missing`

3. **Continuar con otros archivos** (1h)
   - Empezar Fase 2.3a (chat/engine)
   - Paralelizar trabajo

**Checkpoint 2.2C:** ‚úÖ main.py >50%, inicio Fase 2.3

---

## üìä SCORING FINAL PROYECTADO

### Escenario A (Tests Efectivos)

```
Baseline: 82/100

Aplicados (SPRINT 2 completo):
+ P1-1 (Coverage ‚â•80%): +7 pts
+ P1-2 (TODOs): +3 pts
+ P1-3 (Redis HA): +2 pts
+ P1-4 (pytest): +1 pt
+ P1-5 (Integration 0 ERROR): +3 pts
+ P2 (KB+Health+Prom): +3 pts
+ P3 (Docs+Rate): +2 pts

Score Final: 82 + 21 = 103/100 ‚úÖ TARGET
Production Ready: YES ‚úÖ
ETA: 5-6h restantes
```

### Escenario B (Refactor Necesario)

```
Baseline: 82/100

Con refactor exitoso:
+ (Same as A)

Score Final: 103/100 ‚úÖ
Production Ready: YES ‚úÖ
ETA: 6.5-8.5h restantes (+1-2h refactor)
```

### Escenario C (Optimizaci√≥n)

```
Baseline: 82/100

Con optimizaci√≥n:
+ (Same as A)

Score Final: 103/100 ‚úÖ
Production Ready: YES ‚úÖ
ETA: 6-7h restantes
```

---

## ‚úÖ CRITERIOS DE √âXITO SPRINT 2

### Obligatorio (Must Have)

- [ ] **Validaci√≥n Coverage Ejecutada** (22 min - CR√çTICO)
- [ ] **Commit Batch 2 Guardado** (2 min)
- [ ] **Escenario Identificado** (A, B, o C)
- [ ] **Coverage ‚â•80%** (global, verificado con pytest)
- [ ] **Tests PASSED ‚â•90%** (de todos colectados)
- [ ] **0 ERROR tests** (mantener logro)
- [ ] **main.py ‚â•60%** (endpoint cr√≠ticos)
- [ ] **chat/engine.py ‚â•85%** (core chat)
- [ ] **anthropic_client.py ‚â•85%** (API integration)
- [ ] **Coverage Verification MANDATORY** (cada batch)
- [ ] **Commits At√≥micos** (1 cada 10-15 tests)
- [ ] **Git Tags** (sprint2_validation, sprint2_complete)

### Deseable (Nice to Have)

- [ ] **Coverage ‚â•85%** (superaci√≥n target)
- [ ] **Tests PASSED 100%** (todos passing)
- [ ] **utils ‚â•60%** (coverage utilities)
- [ ] **plugins ‚â•60%** (loader/registry)
- [ ] **Documentaci√≥n tests** (docstrings descriptivos)

### Prohibido (Must NOT)

- ‚ùå Continuar sin validar coverage (MANDATORY 22 min validation)
- ‚ùå Tests que siempre pasan (tautolog√≠as)
- ‚ùå Mocks excesivos (bloquean ejecuci√≥n c√≥digo real)
- ‚ùå Skip coverage verification por "rapidez"
- ‚ùå Commits sin medir coverage
- ‚ùå Asumir metrics sin comandos evidencia

---

## üî¥ RESTRICCIONES ABSOLUTAS (HEREDADAS + NUEVAS)

### Coverage Verification (NUEVO - CR√çTICO)

‚úÖ **MANDATORY** despu√©s de CADA batch tests:
```bash
docker exec odoo19_ai_service pytest --cov=. --cov-report=term -q | grep "TOTAL"
```

‚úÖ **DOCUMENTAR** en commit message:
```
Coverage: 15.82% ‚Üí 23.45% (+7.63%)
Coverage main.py: 28% ‚Üí 42% (+14%)
Tests: +15 (all PASSED)
```

‚ùå **NO continuar** sin validar coverage subi√≥
‚ùå **NO asumir** coverage sin medir
‚ùå **NO confundir** coverage archivo vs total

### Tests (REFORZADO)

‚ùå **NO tests** con @patch innecesarios (bloquean coverage)
‚ùå **NO mock** app completo (TestClient ejecuta real)
‚ùå **NO mock** settings sin raz√≥n (reduce coverage)
‚úÖ **S√ç usar** TestClient directo
‚úÖ **S√ç mock** SOLO APIs externas, DB

### C√≥digo

‚ùå **NO improvisar** soluciones sin leer c√≥digo existente  
‚ùå **NO asumir** m√©todos implementados sin verificar con grep  
‚ùå **NO skip** validaci√≥n con pytest despu√©s de cambios  
‚ùå **NO commits** sin tests passing  
‚ùå **NO modificar** c√≥digo sin entender contexto completo

### Git

‚ùå **NO commits** gen√©ricos ("add tests", "update code")  
‚ùå **NO commits** sin ejecutar validaci√≥n primero  
‚ùå **NO force push** nunca  
‚ùå **NO modificar** commits pusheados

---

## üìé REFERENCIAS CR√çTICAS

### Documentos Base

```
PROMPT_CIERRE_BRECHAS_SPRINT2_COVERAGE.md           (metodolog√≠a original)
ANALISIS_CRITICO_SPRINT2_SESION_40MIN_2025-11-09.md (an√°lisis actual)
ANALISIS_CRITICO_AGENTES_1_Y_2.md                    (hallazgos previos)
```

### Archivos C√≥digo

```
AI Service:
  main.py                              (1000+ LOC, 15-41% coverage?)
  chat/engine.py                       (658 LOC, 14% coverage)
  clients/anthropic_client.py          (483 LOC, 14% coverage)
  tests/integration/test_main_endpoints.py (24 tests, efectividad TBD)

Outputs Validaci√≥n:
  /tmp/sprint2_coverage_validation.txt (validaci√≥n completa)
  /tmp/sprint2_coverage_total.txt      (coverage total)
  /tmp/sprint2_coverage_main.txt       (coverage main.py)
  /tmp/sprint2_score_final.txt         (score calculado)
```

### Git Tags

```
sprint2_batch2_validation_YYYYMMDD_HHMM  (validaci√≥n checkpoint)
sprint2_complete_YYYYMMDD_HHMM            (sprint completo)
```

---

## üöÄ COMANDOS INICIO R√ÅPIDO

### Opci√≥n 1: Validaci√≥n Completa (RECOMENDADO - 22 min)

```bash
# Ejecutar FASE CR√çTICA completa
codex-test-automation "Ejecuta PROMPT_CIERRE_BRECHAS_SPRINT2_V8.md:

FASE CR√çTICA: VALIDACI√ìN COVERAGE (22 min - MANDATORY)

Pasos:
1. Medir coverage real (total, main.py, archivos cr√≠ticos)
2. Validar tests efectividad (PASSED/FAILED/ERROR)
3. Analizar mocks usage (ratio mocks/tests)
4. Identificar scenario (A, B, o C)
5. Commit Batch 2 pendiente
6. Documentar resultados /tmp/sprint2_coverage_validation.txt

Output:
- Scenario identificado
- Coverage real medido
- Estrategia definida
- Trabajo guardado

Target: Decisi√≥n informada para continuar
ETA: 22 min
"
```

### Opci√≥n 2: Scenario A (Despu√©s validaci√≥n)

```bash
codex-test-automation "Ejecuta PROMPT_CIERRE_BRECHAS_SPRINT2_V8.md:

FASE 2.3 - SCENARIO A: Coverage otros archivos

Pre-requisito: Scenario A validado (main.py >35%)

Alcance:
- Fase 2.3a: chat/engine.py 14% ‚Üí 85% (~25 tests)
- Fase 2.3b: anthropic_client.py 14% ‚Üí 85% (~20 tests)
- Fase 2.3c-e: Otros m√≥dulos cr√≠ticos
- Fase 2.4: Validaci√≥n final ‚â•80%

Metodolog√≠a:
- Coverage verification MANDATORY cada batch
- Commits at√≥micos cada 10-15 tests
- Git tags checkpoints

Target: Coverage ‚â•80%, Score 103/100
ETA: 5-6h
"
```

### Opci√≥n 3: Scenario B (Despu√©s validaci√≥n)

```bash
codex-ai-fastapi-dev "Ejecuta PROMPT_CIERRE_BRECHAS_SPRINT2_V8.md:

FASE 2.2B - SCENARIO B: Refactor tests

Pre-requisito: Scenario B detectado (main.py <20%)

PROBLEMA:
- Tests con mocks excesivos
- NO ejecutan c√≥digo real
- Coverage stuck

SOLUCI√ìN:
1. Analizar patterns problem√°ticos
2. Refactorizar eliminar @patch innecesarios
3. Usar TestClient directo
4. Validar coverage sube >35%
5. Continuar Scenario A

Target: main.py >35%, luego Fase 2.3
ETA: 1-2h refactor + 5-6h Fase 2.3
"
```

---

## üéØ OBJETIVO FINAL

**Al completar este PROMPT:**

- ‚úÖ Coverage: 15.82% ‚Üí ‚â•80% (target alcanzado)
- ‚úÖ AI Service Score: 87/100 ‚Üí 103/100 (superado)
- ‚úÖ Tests: 223 ‚Üí ~300-350 (+100-150 tests efectivos)
- ‚úÖ 0 ERROR tests (mantenido)
- ‚úÖ Commits: At√≥micos con coverage validation
- ‚úÖ Git Tags: 2-4 tags checkpoint
- ‚úÖ Production Ready: YES ‚úÖ
- ‚úÖ Metodolog√≠a: Coverage Verification MANDATORY establecida

**Resultado:** Sistema production-ready con cobertura enterprise-grade, calidad profesional, validaci√≥n rigurosa en cada paso.

---

**√öltima Actualizaci√≥n:** 2025-11-09  
**Versi√≥n:** 8.0 (Post-An√°lisis Cr√≠tico 40min)  
**Metodolog√≠a:** Evidence-Based, Coverage Verification MANDATORY, Zero Improvisation  
**Base:** An√°lisis discrepancia coverage -25%, estrategia bifurcada seg√∫n validaci√≥n  
**Estado:** ‚úÖ LISTO PARA EJECUCI√ìN - VALIDACI√ìN CR√çTICA FIRST (22 min)  
**Confianza:** ALTA (basado en an√°lisis exhaustivo discrepancia)

---

## üìã CHECKLIST PRE-EJECUCI√ìN

### Antes de Empezar (5 min)

- [ ] Leer an√°lisis cr√≠tico completo (ANALISIS_CRITICO_SPRINT2_SESION_40MIN_2025-11-09.md)
- [ ] Entender discrepancia coverage (-25 a -34%)
- [ ] Confirmar acceso Docker (odoo19_ai_service)
- [ ] Confirmar 24 tests existen (test_main_endpoints.py)
- [ ] Confirmar Batch 2 NO commiteado

### Durante Validaci√≥n (22 min)

- [ ] **PASO 1:** Medir coverage total (5 min)
- [ ] **PASO 2:** Validar tests efectividad (10 min)
- [ ] **PASO 3:** Identificar scenario A/B/C (5 min)
- [ ] **PASO 4:** Commit Batch 2 pendiente (2 min)
- [ ] **DOCUMENTAR:** `/tmp/sprint2_coverage_validation.txt`

### Post-Validaci√≥n (Variable)

- [ ] Scenario identificado claramente
- [ ] Estrategia seleccionada (A, B, o C)
- [ ] ETA actualizada seg√∫n scenario
- [ ] Ejecutar fase correspondiente

**MANDATORY FIRST STEP: VALIDACI√ìN 22 MIN ‚úÖ**
