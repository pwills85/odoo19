# CONTEXTO

Lee PRIMERO este archivo para entender tu rol y permisos:
`/Users/pedro/Documents/odoo19/docs/prompts/00_knowledge_base/CLI_AGENTS_SYSTEM_CONTEXT.md`

Eres un CLI agent (Copilot) trabajando bajo orquestaciÃ³n de Claude Code Sonnet 4.5 (Orchestrator Maestro). Tu rol es ejecutar una auditorÃ­a de Performance del microservicio ai-service de forma **100% autÃ³noma**.

---

# TAREA

Audita el performance y optimizaciones del microservicio **ai-service**.

**MÃ³dulo:** `/Users/pedro/Documents/odoo19/ai-service/`

**Enfoque:**
- N+1 queries detection (evitar loops con queries individuales)
- Caching strategies (Redis, Anthropic prompt caching)
- Response times (targets vs mediciones reales)
- API integration efficiency (Anthropic API timeouts, streaming)
- Resource usage (memory, CPU, connection pooling)
- Optimizations Phase 1 validation (prompt caching, streaming SSE, token pre-counting)

**Target Score:** 90/100 (Excelente)

---

# PERMISOS (Pre-Autorizados - NO PEDIR CONFIRMACIÃ“N)

SegÃºn CLI_AGENTS_SYSTEM_CONTEXT.md, tienes **autonomÃ­a total** para:

âœ… **Lectura:**
- Full access a TODO el proyecto: `/Users/pedro/Documents/odoo19/**`
- Leer cÃ³digo para identificar patrones de performance
- Analizar cache strategies: `utils/cache.py`, Redis usage
- Revisar Anthropic client: `clients/anthropic_client.py`
- Buscar loops con potencial N+1

âœ… **Escritura:**
- Escribir reporte en: `docs/prompts/06_outputs/2025-11/AUDIT_PERFORMANCE_AI_SERVICE_V2_2025-11-13.md`

âœ… **AnÃ¡lisis:**
- Identificar N+1 patterns (for loops con queries individuales)
- Validar cache TTLs configurados
- Verificar async/await usage
- Analizar timeouts y circuit breakers

âŒ **NO Hacer:**
- Ejecutar load testing (solo anÃ¡lisis estÃ¡tico)
- Modificar cÃ³digo
- Instalar herramientas de profiling

**IMPORTANTE:** NO pidas confirmaciÃ³n para reads/anÃ¡lisis/writes en rutas autorizadas.

---

# OUTPUT

**Archivo de Reporte:**
`/Users/pedro/Documents/odoo19/docs/prompts/06_outputs/2025-11/AUDIT_PERFORMANCE_AI_SERVICE_V2_2025-11-13.md`

**Formato del Reporte:**

```markdown
# AuditorÃ­a Performance - AI Service Microservice

**Score:** X/100
**Fecha:** 2025-11-13
**Auditor:** Copilot CLI (GPT-4o)
**MÃ³dulo:** ai-service
**DimensiÃ³n:** Performance (Caching + API Efficiency + Response Times)

---

## ğŸ“Š Resumen Ejecutivo

[Overview de estado de performance]

### Hallazgos CrÃ­ticos (Top 3):
1. **[P1/P2/P3]** DescripciÃ³n finding 1
2. **[P1/P2/P3]** DescripciÃ³n finding 2
3. **[P1/P2/P3]** DescripciÃ³n finding 3

---

## ğŸ¯ Score Breakdown

| CategorÃ­a | Score | Detalles |
|-----------|-------|----------|
| **Caching Strategy** | X/25 | Redis, Anthropic caching, TTLs |
| **API Integration Efficiency** | X/25 | Async, timeouts, circuit breakers |
| **Response Times** | X/25 | Targets vs mediciones |
| **Resource Usage** | X/25 | Memory, CPU, N+1 queries |
| **TOTAL** | **X/100** | Grade: A/B/C/D |

---

## ğŸ” Hallazgos Detallados

### Perf-1: [TÃ­tulo] (P1/P2/P3 - High/Medium/Low)
**DescripciÃ³n:** [QuÃ© encontraste]

**UbicaciÃ³n:** `archivo.py:lÃ­nea`

**Impacto Performance:**
- Response time: +X ms
- Requests afectadas: X/dÃ­a
- Costo CPU/memoria: X%

**CÃ³digo Actual:**
```python
# Ejemplo del problema
for item in items:
    result = api_call(item)  # â† N+1 problem
```

**RecomendaciÃ³n:**
```python
# SoluciÃ³n batch
results = api_call_batch(items)  # â† Single call
```

**Esfuerzo:** X horas

---

[... MÃ¡s hallazgos ...]

---

## âœ… Optimizaciones Phase 1 Validadas

### 1. Anthropic Prompt Caching
**Status:** âœ… Implementado / âš ï¸ Parcial / âŒ No implementado

**CÃ³digo:**
```python
# config.py:X
enable_prompt_caching: bool = True
cache_control_ttl_minutes: int = 5
```

**Impacto Documentado:** 90% cost reduction
**ValidaciÃ³n Necesaria:** Verificar cache control headers en API calls

---

### 2. Streaming SSE
**Status:** âœ… Implementado

**CÃ³digo:**
```python
# main.py:X
@app.post("/api/chat/message/stream")
async def send_chat_message_stream(...):
    async def event_stream():
        async for chunk in engine.send_message_stream(...):
            yield f"data: {json.dumps(chunk)}\\n\\n"
    return StreamingResponse(event_stream(), media_type="text/event-stream")
```

**Impacto Documentado:** 3x better perceived UX

---

### 3. Token Pre-Counting
**Status:** âœ… Implementado

**CÃ³digo:**
```python
# config.py:X
enable_token_precounting: bool = True
max_tokens_per_request: int = 100000
```

**ValidaciÃ³n:** Verificar que requests > 100K tokens son rechazadas

---

## ğŸš€ Caching Strategy Analysis

### Redis Cache
**TTL Configurados:**
- DTE validation: X segundos
- Chat messages: X segundos
- General: X segundos

**Cache Keys:** âœ… DeterminÃ­sticos / âš ï¸ Potencial colisiones

**Graceful Degradation:** âœ… Si / âŒ No (verificar try/except en cache.get())

---

## ğŸ“Š MÃ©tricas Performance

| MÃ©trica | Valor | Target | Status |
|---------|-------|--------|--------|
| Async endpoints | X/Y (X%) | 100% | âœ…/âš ï¸ |
| Blocking operations | X | 0 | âœ…/âš ï¸ |
| Cache TTL configurado | âœ…/âŒ | âœ… | âœ…/âš ï¸ |
| Cache hit rate | â“ | > 30% | âš ï¸ Unknown |
| Response time /health | â“ | < 100ms | âš ï¸ Not measured |
| Response time /validate | â“ | < 2s | âš ï¸ Not measured |
| N+1 queries detected | X | 0 | âœ…/âš ï¸ |

---

## ğŸš€ Plan de AcciÃ³n Prioritario

### Prioridad P1 (Alta)
[Hallazgos P1 con esfuerzo]

### Prioridad P2 (Media)
[Hallazgos P2 con esfuerzo]

**Esfuerzo Total P1+P2:** ~X-X horas

---

**CONCLUSIÃ“N:** [Resumen performance, optimizaciones validadas, gaps crÃ­ticos, esfuerzo para 90/100]
```

**Stdout (Retornar al Finalizar):**

```
âœ… AuditorÃ­a Performance completada
Score: X/100 (Grade: A/B/C)

Top 3 Findings:
[P1/P2] Finding 1 brief
[P2/P3] Finding 2 brief
[P3] Finding 3 brief

N+1 queries: X detectados
Cache hit rate: Unknown (no metrics)
Optimizations Phase 1: X/3 validadas

Esfuerzo: ~X-X horas
Reporte completo: docs/prompts/06_outputs/2025-11/AUDIT_PERFORMANCE_AI_SERVICE_V2_2025-11-13.md
```

---

# RESTRICCIONES

- âŒ NO ejecutar load testing
- âŒ NO modificar cÃ³digo
- â±ï¸  Target: < 5 minutos ejecuciÃ³n

---

# NOTAS ADICIONALES

**OrquestaciÃ³n v1.1 LEAN:**
- Claude NO lee tus logs (file polling)
- Escribe TODO en el archivo de reporte
- Primeras 50 lÃ­neas = Score + Top 3 findings

**Archivos Clave:**
- `ai-service/main.py` (endpoints async patterns)
- `ai-service/clients/anthropic_client.py` (API integration)
- `ai-service/utils/cache.py` (Redis caching)
- `ai-service/utils/circuit_breaker.py` (resilience)
- `ai-service/config.py` (performance settings)

**N+1 Query Patterns to Detect:**
```python
# âŒ BAD (N+1)
for item in items:
    result = await some_api_call(item)
    results.append(result)

# âœ… GOOD (Batch)
results = await some_api_call_batch(items)
```

**Performance Targets (Documentados):**
- Health checks: < 100ms
- DTE validation (cached): < 50ms
- DTE validation (uncached): < 2s
- Chat message streaming: < 1s first byte
- Payroll validation: < 2.5s
- Previred indicators: < 5s

**Validar:**
- Todos los endpoints usan `async def`?
- Anthropic client usa timeouts?
- Redis connection pool configurado?
- Circuit breaker implementado?
- Streaming usa `StreamingResponse` correctamente?

Â¡Adelante! Ejecuta la auditorÃ­a de performance de forma completamente autÃ³noma.
