# Auditoría Performance - AI Service Microservice

**ROL:** Agente Auditor Performance Expert

**OBJETIVO:** Auditar performance del microservicio: N+1 queries, caching estrategias, response times, optimizaciones

**MÓDULO EN ALCANCE:**
- `/Users/pedro/Documents/odoo19/ai-service/`
- 20+ endpoints REST + SSE streaming
- Integraciones: Anthropic API, Redis, Odoo

**CONTEXTO CRÍTICO:**
- Microservicio con optimizaciones recientes (Phase 1):
  - Prompt caching (90% cost reduction)
  - Streaming SSE (3x better perceived UX)
  - Token pre-counting (cost control)
- Target: < 2s response time p95 para endpoints críticos

**CRITERIOS DE AUDITORÍA:**

## 1. Database & ORM Performance

### 1.1 N+1 Queries
- ⚠️ Buscar patrones N+1 en código Python (loops con queries individuales)
- ⚠️ Verificar uso correcto de `prefetch_related` / `select_related` si aplica
- ⚠️ Identificar queries repetitivas dentro de loops

### 1.2 Query Optimization
- ⚠️ Verificar que queries tienen índices apropiados (si se usa DB local)
- ⚠️ Validar que NO hay `SELECT *` innecesarios
- ⚠️ Verificar uso de pagination en listas grandes

## 2. Caching Strategy

### 2.1 Redis Cache
- ✅ **BUENO:** Cache helpers implementados (`_get_cached_response`, `_set_cached_response`)
- ✅ TTL configurado: 15 min (DTE validation), 5 min (chat), 1 hora (general)
- ✅ Cache keys deterministas (MD5 hash de data)
- ⚠️ Verificar cache hit rate (target: > 30%)
- ⚠️ Validar que cache invalidation funciona correctamente
- ⚠️ Verificar que cache failures NO rompen flujo (graceful degradation - main.py:911)

### 2.2 Anthropic Prompt Caching
- ✅ **EXCELENTE:** Prompt caching habilitado (config.py:54)
- ✅ 90% cost reduction documentado
- ⚠️ Verificar que cache control se envía correctamente a Anthropic API
- ⚠️ Validar que prompts largos (> 1024 tokens) usan caching

### 2.3 Cache Misses
- ⚠️ Identificar endpoints con bajo cache hit rate
- ⚠️ Verificar que cache keys incluyen todos los parámetros relevantes

## 3. API Integrations Performance

### 3.1 Anthropic API
- ✅ Async client (`anthropic.AsyncAnthropic`)
- ✅ Timeouts configurados (60s - config.py:49)
- ✅ Retries configurados (max 3 - config.py:50)
- ✅ Streaming implementado (reduce perceived latency 3x)
- ⚠️ Verificar circuit breaker para failures consecutivos
- ⚠️ Validar que requests NO bloquean event loop

### 3.2 Redis Sentinel
- ✅ Redis cluster con Sentinel (high availability)
- ⚠️ Verificar que reads van a replicas (read-only mode)
- ⚠️ Validar latency < 100ms (main.py:560 warning)
- ⚠️ Verificar connection pooling configurado

### 3.3 External Services (Previred, SII)
- ⚠️ Verificar timeouts configurados para scraping
- ⚠️ Validar que downloads pesados (PDF) NO bloquean requests
- ⚠️ Verificar rate limiting para evitar bans

## 4. Response Times

### 4.1 Target Benchmarks
- **Health checks:** < 100ms
- **DTE validation:** < 2s (con cache: < 50ms)
- **Chat message:** < 3s (streaming: perceived < 1s)
- **Payroll validation:** < 2.5s
- **Previred indicators:** < 5s (scraping + parsing)

### 4.2 Slow Endpoints
- ⚠️ Identificar endpoints > 2s response time
- ⚠️ Verificar bottlenecks (DB, API external, CPU)
- ⚠️ Validar que NO hay blocking I/O en async functions

### 4.3 Middleware Overhead
- ✅ Observability middleware (timing tracking)
- ⚠️ Verificar que middleware overhead < 10ms
- ⚠️ Validar que logging NO es bloqueante

## 5. Resource Usage

### 5.1 Memory
- ⚠️ Verificar que NO hay memory leaks (Redis connections, cache growth)
- ⚠️ Validar limits para inputs grandes (max_items, max_length en Pydantic)
- ⚠️ Verificar que history no crece indefinidamente (max 100 items - main.py:314)

### 5.2 CPU
- ⚠️ Identificar operaciones CPU-intensive (parsing, validation)
- ⚠️ Verificar que NO hay regex ineficientes (catastrophic backtracking)
- ⚠️ Validar que JSON serialization es eficiente

### 5.3 Network
- ⚠️ Verificar que payloads NO son excesivamente grandes
- ⚠️ Validar compresión para responses grandes (gzip)
- ⚠️ Verificar que streaming reduce memory footprint

## 6. Optimizaciones Recientes (Phase 1 - Validar)

### 6.1 Prompt Caching
- ✅ Implementado (config.py:54)
- ⚠️ Validar que está activo en producción
- ⚠️ Verificar metrics de cost reduction real (target: 90%)

### 6.2 Streaming SSE
- ✅ Implementado (`/api/chat/message/stream`)
- ⚠️ Validar que buffering está disabled (nginx, uvicorn)
- ⚠️ Verificar que perceived UX es 3x mejor vs non-streaming

### 6.3 Token Pre-counting
- ✅ Implementado (config.py:59)
- ⚠️ Validar que requests > 100K tokens son rechazados
- ⚠️ Verificar que cost estimation es precisa

## 7. Load Testing & Scalability

### 7.1 Concurrency
- ⚠️ Verificar que async endpoints manejan carga concurrente
- ⚠️ Validar que NO hay deadlocks (Redis, DB)
- ⚠️ Verificar que connection pools tienen tamaño adecuado

### 7.2 Rate Limiting
- ✅ SlowAPI implementado (20-30 req/min por endpoint)
- ⚠️ Verificar que rate limits NO son demasiado restrictivos
- ⚠️ Validar que rate limiting NO degrada performance significativamente

**COMANDOS ÚTILES:**

```bash
cd /Users/pedro/Documents/odoo19/ai-service

# Check for blocking operations
grep -rn "time\.sleep\|requests\.\(get\|post\)" --include="*.py" --color=always

# Find large functions (performance bottlenecks)
radon cc . -a -s --min C

# Check for inefficient patterns
grep -rn "for .* in.*:\s*.*\.get(" --include="*.py" --color=always  # N+1 pattern

# Redis cache stats (si aplica)
# redis-cli INFO stats | grep keyspace_hits
```

**ENTREGABLE:**

Generar `AUDIT_PERFORMANCE_AI_SERVICE_2025-11-13.md` con:

1. **Resumen Ejecutivo** (3-5 bottlenecks críticos)

2. **Score Performance:** [X]/100
   - Caching Strategy: [X]/25
   - API Integration Efficiency: [X]/25
   - Response Times: [X]/25
   - Resource Usage: [X]/25

3. **Matriz de Hallazgos:**

| ID | Endpoint/Module | Issue | Criticidad | Impact | Recomendación |
|----|----------------|-------|-----------|---------|---------------|
| P1 | endpoint | Slow response | P0/P1/P2 | +2s latency | ... |

4. **Métricas:**
   - Endpoints > 2s: [N]
   - N+1 queries detected: [N]
   - Cache hit rate: [X]%
   - Blocking operations: [N]
   - Memory leaks: [N]

5. **Benchmarks (si aplica):**
   - Health check: [X]ms
   - DTE validation (cached): [X]ms
   - DTE validation (uncached): [X]ms
   - Chat message (streaming): [X]ms perceived

**OUTPUT FORMAT (OBLIGATORIO):**

```markdown
**Score:** [N]/100

**Fecha:** 2025-11-13
**Auditor:** Codex CLI (GPT-4-turbo)
**Módulo:** ai-service
**Dimensión:** Performance

## Hallazgos

[P0] Critical performance bottleneck (endpoint: +5s)
[P1] High priority optimization needed (N+1 query)
[P2] Medium priority improvement (cache miss rate low)
```

**RESTRICCIONES:**
- Modo solo lectura
- Basar análisis en código real + métricas actuales
- Priorizar optimizaciones con mayor ROI (P0/P1)
- Incluir impacto cuantificado cuando sea posible
