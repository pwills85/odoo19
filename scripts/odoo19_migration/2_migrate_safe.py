#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ODOO 19 CE - SCRIPT DE MIGRACIÃ“N SEGURA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Fecha: 2025-11-11
Autor: Sistema de MigraciÃ³n Odoo 19

OBJETIVO:
Aplicar correcciones SIN ERRORES basÃ¡ndose en los hallazgos de auditorÃ­a,
con confirmaciÃ³n en un trabajo retroalimentado hasta dejar al 100% los mÃ³dulos.

CARACTERÃSTICAS:
- Lee hallazgos desde audit_findings.json
- Modo dry-run por defecto (preview sin aplicar cambios)
- Backup automÃ¡tico de archivos antes de modificar
- AplicaciÃ³n inteligente segÃºn estrategia de reemplazo
- ValidaciÃ³n despuÃ©s de cada cambio
- Rollback automÃ¡tico si falla validaciÃ³n

SEGURIDAD:
- NUNCA modifica archivos sin backup
- NUNCA aplica cambios en masa sin validaciÃ³n
- SIEMPRE verifica sintaxis despuÃ©s de cambios

SALIDA:
- migration_log.txt: Log detallado de cambios aplicados
- migration_results.json: Resultados estructurados
- Backups en: {file_path}.backup_{timestamp}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import re
import json
import yaml
import shutil
import logging
import ast
import xml.etree.ElementTree as ET
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Tuple

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIONES DE BACKUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_backup(file_path: str) -> str:
    """Crea un backup timestamped del archivo."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"{file_path}.backup_{timestamp}"
    
    try:
        shutil.copy2(file_path, backup_path)
        logger.info(f"  âœ“ Backup creado: {backup_path}")
        return backup_path
    except Exception as e:
        logger.error(f"  âœ— Error creando backup de {file_path}: {e}")
        raise


def restore_backup(backup_path: str, original_path: str):
    """Restaura un archivo desde su backup."""
    try:
        shutil.copy2(backup_path, original_path)
        logger.info(f"  âœ“ Restaurado desde backup: {backup_path}")
    except Exception as e:
        logger.error(f"  âœ— Error restaurando backup {backup_path}: {e}")
        raise


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIONES DE VALIDACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def validate_python_syntax(file_path: str) -> Tuple[bool, str]:
    """Valida sintaxis Python usando AST."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            code = f.read()
        ast.parse(code, filename=file_path)
        return True, "Sintaxis OK"
    except SyntaxError as e:
        return False, f"Error de sintaxis en lÃ­nea {e.lineno}: {e.msg}"
    except Exception as e:
        return False, f"Error validando sintaxis: {e}"


def validate_xml_syntax(file_path: str) -> Tuple[bool, str]:
    """Valida sintaxis XML."""
    try:
        ET.parse(file_path)
        return True, "XML OK"
    except ET.ParseError as e:
        return False, f"Error XML: {e}"
    except Exception as e:
        return False, f"Error validando XML: {e}"


def validate_file(file_path: str) -> Tuple[bool, str]:
    """Valida un archivo segÃºn su tipo."""
    if file_path.endswith('.py'):
        return validate_python_syntax(file_path)
    elif file_path.endswith('.xml'):
        return validate_xml_syntax(file_path)
    else:
        return True, "Tipo de archivo no requiere validaciÃ³n"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIONES DE MIGRACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def apply_regex_replacement(file_path: str, pattern: Dict, dry_run: bool = True) -> Tuple[bool, str, Dict]:
    """Aplica un reemplazo regex en un archivo."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            original_content = f.read()
        
        regex = re.compile(pattern['regex_search'], re.MULTILINE | re.DOTALL)
        new_content = regex.sub(pattern['regex_replace'], original_content)
        
        if new_content == original_content:
            return False, "Sin cambios necesarios", {}
        
        changes_count = len(regex.findall(original_content))
        
        if not dry_run:
            # Crear backup antes de modificar
            backup_path = create_backup(file_path)
            
            # Escribir cambios
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            # Validar sintaxis
            valid, message = validate_file(file_path)
            if not valid:
                # Rollback si falla validaciÃ³n
                logger.error(f"  âœ— ValidaciÃ³n fallÃ³: {message}")
                restore_backup(backup_path, file_path)
                return False, f"Rollback aplicado - {message}", {}
            
            return True, f"Aplicado: {changes_count} cambios", {'backup': backup_path, 'changes': changes_count}
        else:
            return True, f"DRY RUN: {changes_count} cambios serÃ­an aplicados", {'changes': changes_count}
    
    except Exception as e:
        logger.error(f"  âœ— Error aplicando migraciÃ³n: {e}")
        return False, str(e), {}


def migrate_sql_constraints(file_path: str, finding: Dict, dry_run: bool = True) -> Tuple[bool, str, Dict]:
    """Migra _sql_constraints a models.Constraint (requiere anÃ¡lisis AST)."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        tree = ast.parse(content, filename=file_path)
        
        # Buscar _sql_constraints
        modifications = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name) and target.id == '_sql_constraints':
                        # Parsear el valor (lista de tuplas)
                        if isinstance(node.value, ast.List):
                            for elt in node.value.elts:
                                if isinstance(elt, ast.Tuple) and len(elt.elts) == 3:
                                    constraint_name = ast.literal_eval(elt.elts[0])
                                    constraint_sql = ast.literal_eval(elt.elts[1])
                                    constraint_message = ast.literal_eval(elt.elts[2])
                                    
                                    # Generar nuevo cÃ³digo
                                    new_constraint = f"    {constraint_name} = models.Constraint('{constraint_sql}', '{constraint_message}')\n"
                                    modifications.append({
                                        'line': node.lineno,
                                        'old_code': ast.get_source_segment(content, node),
                                        'new_code': new_constraint
                                    })
        
        if not modifications:
            return False, "No se encontraron _sql_constraints activos", {}
        
        if not dry_run:
            # Aplicar modificaciones (por ahora, requiere revisiÃ³n manual)
            logger.warning("  âš  MigraciÃ³n de _sql_constraints requiere revisiÃ³n manual")
            logger.info("  ðŸ’¡ Sugerencia de migraciÃ³n:")
            for mod in modifications:
                logger.info(f"     LÃ­nea {mod['line']}: {mod['new_code']}")
            return False, "Requiere intervenciÃ³n manual", {'modifications': modifications}
        else:
            return True, f"DRY RUN: {len(modifications)} constraints serÃ­an migrados (requiere revisiÃ³n manual)", {'modifications': modifications}
    
    except Exception as e:
        logger.error(f"  âœ— Error migrando _sql_constraints: {e}")
        return False, str(e), {}


def migrate_attrs_xml(file_path: str, finding: Dict, dry_run: bool = True) -> Tuple[bool, str, Dict]:
    """Migra attrs= en XML a expresiones Python directas (complejo)."""
    # Esta es una migraciÃ³n compleja que requiere parsing XML y transformaciÃ³n de lÃ³gica
    # Por ahora, se marca como manual
    logger.warning("  âš  MigraciÃ³n de attrs= requiere revisiÃ³n manual (transformaciÃ³n compleja)")
    return False, "Requiere intervenciÃ³n manual - transformaciÃ³n attrs= a expresiÃ³n Python", {}


def apply_migration(file_path: str, finding: Dict, pattern: Dict, dry_run: bool = True) -> Tuple[bool, str, Dict]:
    """Aplica migraciÃ³n segÃºn la estrategia definida."""
    strategy = pattern.get('replacement_strategy', 'regex')
    
    if strategy == 'ast_analysis':
        if pattern['id'] == 'sql_constraints':
            return migrate_sql_constraints(file_path, finding, dry_run)
        else:
            # Otros anÃ¡lisis AST
            return apply_regex_replacement(file_path, pattern, dry_run)
    elif strategy == 'ast_xml_analysis':
        if pattern['id'] == 'attrs_xml':
            return migrate_attrs_xml(file_path, finding, dry_run)
        else:
            return apply_regex_replacement(file_path, pattern, dry_run)
    elif strategy == 'manual':
        return False, "Requiere intervenciÃ³n manual", {}
    elif strategy == 'audit_only':
        return False, "Solo auditorÃ­a, no se aplica migraciÃ³n automÃ¡tica", {}
    else:
        # Estrategia regex estÃ¡ndar
        return apply_regex_replacement(file_path, pattern, dry_run)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N PRINCIPAL DE MIGRACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_migration(findings: List[Dict], config: Dict, dry_run: bool = True) -> Dict:
    """Ejecuta la migraciÃ³n basada en hallazgos de auditorÃ­a."""
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    logger.info(f"  INICIANDO MIGRACIÃ“N {'(DRY RUN)' if dry_run else '(REAL)'}")
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # Crear mapa de patrones por ID
    patterns_map = {p['id']: p for p in config['deprecations']}
    
    # Agrupar hallazgos por archivo y patrÃ³n
    by_file = {}
    for finding in findings:
        file_path = finding['file']
        pattern_id = finding['id']
        
        if file_path not in by_file:
            by_file[file_path] = {}
        if pattern_id not in by_file[file_path]:
            by_file[file_path][pattern_id] = []
        by_file[file_path][pattern_id].append(finding)
    
    # Resultados
    results = {
        'timestamp': datetime.now().isoformat(),
        'dry_run': dry_run,
        'total_files': len(by_file),
        'successful': 0,
        'failed': 0,
        'manual_required': 0,
        'skipped': 0,
        'details': []
    }
    
    # Procesar cada archivo
    for file_path, patterns in by_file.items():
        logger.info(f"\nProcesando: {file_path}")
        
        for pattern_id, file_findings in patterns.items():
            pattern = patterns_map[pattern_id]
            logger.info(f"  PatrÃ³n: {pattern['name']} ({len(file_findings)} ocurrencias)")
            
            # Aplicar migraciÃ³n solo a la primera ocurrencia (para evitar conflictos)
            # Las demÃ¡s se procesarÃ¡n en la siguiente iteraciÃ³n
            finding = file_findings[0]
            
            success, message, details = apply_migration(file_path, finding, pattern, dry_run)
            
            result = {
                'file': file_path,
                'pattern_id': pattern_id,
                'pattern_name': pattern['name'],
                'success': success,
                'message': message,
                'details': details,
                'priority': pattern['priority']
            }
            results['details'].append(result)
            
            if success:
                results['successful'] += 1
                logger.info(f"  âœ“ {message}")
            elif 'manual' in message.lower():
                results['manual_required'] += 1
                logger.warning(f"  âš  {message}")
            else:
                results['failed'] += 1
                logger.error(f"  âœ— {message}")
    
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Script de MigraciÃ³n Segura Odoo 19 CE')
    parser.add_argument('--dry-run', action='store_true', default=True,
                        help='Modo dry-run (preview sin aplicar cambios)')
    parser.add_argument('--apply', action='store_true',
                        help='Aplicar cambios reales (desactiva dry-run)')
    parser.add_argument('--priority', choices=['P0', 'P1', 'P2'], default=None,
                        help='Aplicar solo migraciones de una prioridad especÃ­fica')
    args = parser.parse_args()
    
    dry_run = not args.apply  # Si --apply estÃ¡ presente, dry_run=False
    
    PROJECT_ROOT = Path(__file__).parent.parent.parent
    CONFIG_PATH = PROJECT_ROOT / 'scripts' / 'odoo19_migration' / 'config' / 'deprecations.yaml'
    FINDINGS_PATH = PROJECT_ROOT / 'audit_findings.json'
    RESULTS_PATH = PROJECT_ROOT / ('migration_results_dryrun.json' if dry_run else 'migration_results.json')
    LOG_PATH = PROJECT_ROOT / ('migration_log_dryrun.txt' if dry_run else 'migration_log.txt')
    
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    logger.info("  SISTEMA DE MIGRACIÃ“N SEGURA ODOO 19 CE")
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    if not dry_run:
        logger.warning("âš ï¸  MODO REAL ACTIVADO - Se aplicarÃ¡n cambios")
        logger.warning("âš ï¸  Se crearÃ¡n backups automÃ¡ticos de cada archivo")
    else:
        logger.info("â„¹ï¸  MODO DRY RUN - Solo preview, sin aplicar cambios")
    
    # Validar paths
    if not FINDINGS_PATH.exists():
        logger.error(f"âœ— Archivo de hallazgos no encontrado: {FINDINGS_PATH}")
        logger.error("  Ejecuta primero: python 1_audit_deprecations.py")
        return 1
    
    if not CONFIG_PATH.exists():
        logger.error(f"âœ— Archivo de configuraciÃ³n no encontrado: {CONFIG_PATH}")
        return 1
    
    # Cargar datos
    with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    with open(FINDINGS_PATH, 'r', encoding='utf-8') as f:
        findings_data = json.load(f)
        findings = findings_data['findings']
    
    # Filtrar por prioridad si se especificÃ³
    if args.priority:
        findings = [f for f in findings if f['priority'] == args.priority]
        logger.info(f"Filtrando solo prioridad: {args.priority} ({len(findings)} hallazgos)")
    
    # Ejecutar migraciÃ³n
    results = run_migration(findings, config, dry_run)
    
    # Guardar resultados
    with open(RESULTS_PATH, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # Resumen
    logger.info("")
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    logger.info("  MIGRACIÃ“N COMPLETADA")
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    logger.info(f"  Total archivos: {results['total_files']}")
    logger.info(f"  Exitosos: {results['successful']}")
    logger.info(f"  Fallidos: {results['failed']}")
    logger.info(f"  Requieren manual: {results['manual_required']}")
    logger.info("")
    logger.info(f"  Resultados: {RESULTS_PATH}")
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    if not dry_run and results['successful'] > 0:
        logger.info("")
        logger.info("ðŸ“‹ SIGUIENTE PASO:")
        logger.info("  Ejecutar: python 3_validate_changes.py")
    
    return 0


if __name__ == "__main__":
    exit(main())
